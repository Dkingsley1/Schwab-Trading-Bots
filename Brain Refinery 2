import mlx.core as mx
import mlx.nn as nn
import mlx.optimizers as optim
import numpy as np

class TradingBrain(nn.Module):
    """
    Takes the last 5 price points and predicts the next price.
    Larger network for better fit on noisy data.
    """
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Linear(5, 64)
        self.layer2 = nn.Linear(64, 32)
        self.layer3 = nn.Linear(32, 16)
        self.output = nn.Linear(16, 1)

    def __call__(self, x):
        x = nn.relu(self.layer1(x))
        x = nn.relu(self.layer2(x))
        x = nn.relu(self.layer3(x))
        return self.output(x)

def loss_fn(model, x, y):
    return nn.losses.mse_loss(model(x), y)

def make_windows(prices, window=5):
    X = []
    Y = []
    for i in range(len(prices) - window):
        X.append(prices[i:i+window])
        Y.append(prices[i+window])
    X = mx.stack(X).reshape(-1, window)
    Y = mx.stack(Y).reshape(-1, 1)
    return X, Y

def train_brain():
    brain = TradingBrain()
    mx.eval(brain.parameters())

    optimizer = optim.Adam(learning_rate=0.001)

    # Synthetic market data
    t = np.linspace(0, 50, 1000)
    prices = np.sin(t) + np.random.normal(0, 0.1, 1000)
    prices = mx.array(prices, dtype=mx.float32)

    # Normalize
    mean = mx.mean(prices)
    std = mx.std(prices) + 1e-8
    prices = (prices - mean) / std

    # Windowed dataset
    X, Y = make_windows(prices, window=5)
    n = X.shape[0]

    print("Training on simulated price action...")

    loss_and_grad_fn = nn.value_and_grad(brain, loss_fn)

    epochs = 200
    batch_size = 64

    for epoch in range(epochs):
        idx = np.random.permutation(n)

        total_loss = 0.0
        num_batches = 0

        for start in range(0, n, batch_size):
            batch_idx = mx.array(idx[start:start+batch_size])
            xb = mx.take(X, batch_idx, axis=0)
            yb = mx.take(Y, batch_idx, axis=0)

            loss, grads = loss_and_grad_fn(brain, xb, yb)

            optimizer.update(brain, grads)
            mx.eval(brain.parameters(), optimizer.state)

            total_loss += float(loss)
            num_batches += 1

        if epoch % 10 == 0:
            print(f"Epoch {epoch}: Error Level = {total_loss / num_batches:.6f}")

    print("Model training complete.")
    return brain

if __name__ == "__main__":
    trained_model = train_brain()
