import mlx.core as mx
import mlx.nn as nn
import mlx.optimizers as optim
import numpy as np

class TradingBrain(nn.Module):
    """
    Takes the last 5 price points and predicts the next price.
    """
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Linear(5, 32)
        self.layer2 = nn.Linear(32, 16)
        self.output = nn.Linear(16, 1)

    def __call__(self, x):
        x = nn.relu(self.layer1(x))
        x = nn.relu(self.layer2(x))
        return self.output(x)

def loss_fn(model, x, y):
    return nn.losses.mse_loss(model(x), y)

def train_brain():
    brain = TradingBrain()
    mx.eval(brain.parameters())

    optimizer = optim.Adam(learning_rate=0.01)

    # Synthetic market data
    t = np.linspace(0, 50, 500)
    prices = np.sin(t) + np.random.normal(0, 0.1, 500)
    prices = mx.array(prices, dtype=mx.float32)

    print("Training on simulated price action...")

    num_windows = len(prices) - 5

    # Create loss+grad fn once
    loss_and_grad_fn = nn.value_and_grad(brain, loss_fn)

    for epoch in range(100):
        total_loss = 0.0

        for i in range(num_windows):
            x = prices[i:i+5].reshape(1, -1)
            y = prices[i+5:i+6].reshape(1, -1)

            # Note: pass model as first argument
            loss, grads = loss_and_grad_fn(brain, x, y)

            optimizer.update(brain, grads)
            mx.eval(brain.parameters(), optimizer.state)

            total_loss += float(loss)

        if epoch % 10 == 0:
            print(f"Epoch {epoch}: Error Level = {total_loss / num_windows:.6f}")

    print("Model training complete.")
    return brain

if __name__ == "__main__":
    trained_model = train_brain()
